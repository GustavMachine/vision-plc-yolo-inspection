# -*- coding: utf-8 -*-
"""Copia de CV_AutomatizacionB.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s5yauDt8ta2GnRQM38IQdaqlwV4pDFqK

## VISION POR COMPUTADORA
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install tensorflow
# %pip install pyads
import numpy as np
from tensorflow.keras.models import load_model
import pyads
import cv2
import time
from collections import Counter


ipc = pyads.Connection('192.168.57.231.1.1', 851)
ipc.open()
model=load_model("best.pt")
cap = 1  # La cÃ¡mara se inicializa solo cuando se necesita

from ultralytics import YOLO
import pyads
import cv2
import time
from collections import Counter
import torch

# ===========================
# âš™ï¸ CONFIGURACIÃ“N GENERAL
# ===========================

# PLC
ADS_NET_ID = '192.168.57.231.1.1'
ADS_PORT = 851
PLC_TRIGGER_VAR = 'VARIABLES.bVarBool'
PLC_OUTPUT_VAR  = 'VARIABLES.iVarInt'

# CÃ¡mara (DroidCam por IP)
# Si usas DroidCam como stream IP, la URL tÃ­pica es:
#   http://IP:4747/video    (MJPEG)
CAMERA_SOURCE   = "http://10.101.1.180:4747/video"
FRAME_SLEEP     = 0.03   # pausa entre capturas (30 ms)

# Ventana de decisiÃ³n
MAX_FRAMES           = 20     # mÃ¡ximo de frames a analizar por flanco
MAX_CAPTURE_DURATION = 2.0    # mÃ¡ximo tiempo (segundos) por ciclo de captura
MIN_PREDICTIONS      = 5      # mÃ­nimo de predicciones para tomar decisiÃ³n
DOMINANCE_THRESHOLD  = 0.6    # % mÃ­nimo de dominancia para aceptar color (ej. 60%)

# YOLO
MODEL_PATH   = "best.pt"
YOLO_CONF    = 0.45           # ðŸ”½ antes 0.6, ahora mÃ¡s permisivo
YOLO_DEVICE  = 0 if torch.cuda.is_available() else 'cpu'

# Mapeo modelo â†’ lÃ³gica de color â†’ PLC
MODEL_TO_COLOR = {
    "Amarrillo": "amarillo",
    "amarillo": "amarillo",
    "Azul": "azul",
    "azul": "azul",
    "Negro": "negro",
    "negro": "negro",
    "Rojo": "rojo",
    "rojo": "rojo",
    "Otros": "otros",        # clase "Otros" â‰  background
    "otros": "otros",
    "background": "background"
}

COLOR_TO_PLC_VALUE = {
    "amarillo": 1,
    "azul": 2,
    "negro": 3,
    "rojo": 4,
    "otros": 5,              # pieza desconocida / fuera de patrÃ³n
    "background": 5          # no se vio nada claro
}

# ===========================
# ðŸ”Œ CONEXIÃ“N PLC + MODELO
# ===========================

ipc = pyads.Connection(ADS_NET_ID, ADS_PORT)
ipc.open()
print("âœ… Conectado al PLC Beckhoff")

print(f"ðŸ” Cargando modelo YOLO: {MODEL_PATH}")
model = YOLO(MODEL_PATH)
print("âœ… Modelo YOLO cargado correctamente")
print("ðŸ“‹ Clases del modelo:", model.names)

# ===========================
# ðŸŽ¯ PREDICCIÃ“N CON YOLO
# ===========================

def predict_image(frame, model):
    """
    Recibe un frame BGR, lo pasa a YOLO, y devuelve un color lÃ³gico:
    'amarillo', 'azul', 'negro', 'rojo', 'otros' o 'background'.
    """
    if frame is None or frame.size == 0:
        print("âš ï¸ Frame vacÃ­o, devolviendo background")
        return "background"

    try:
        # Dos intentos: conf normal y luego conf mÃ¡s bajo
        for conf_thr in [YOLO_CONF, 0.35]:
            results = model.predict(
                source=frame,
                conf=conf_thr,
                device=YOLO_DEVICE,
                verbose=False
            )
            detections = results[0].boxes

            if len(detections) == 0:
                continue  # probamos con un conf mÃ¡s bajo

            # Tomamos la detecciÃ³n con mayor confianza (primer elemento)
            cls_id = int(detections.cls[0])
            conf   = float(detections.conf[0])
            raw_label = model.names[cls_id]

            # Normalizamos el nombre de la clase
            label = MODEL_TO_COLOR.get(raw_label, "otros")

            print(f"ðŸŽ¯ YOLO (conf={conf_thr:.2f}): {raw_label} -> {label} (conf {conf:.2f})")
            return label

        # Si despuÃ©s de los dos intentos no se detectÃ³ nada
        print("âš ï¸ Sin detecciones incluso con conf bajo, devolviendo background")
        return "background"

    except Exception as e:
        print(f"âŒ Error en predicciÃ³n: {e}")
        return "background"

# ===========================
# ðŸŽ¥ DETECCIÃ“N POR FLANCO
# ===========================

def open_camera(source):
    """
    Abre la cÃ¡mara. 'source' puede ser:
      - Ã­ndice entero (0, 1, 2) para webcam
      - string con URL (DroidCam IP, RTSP, etc.)
    """
    # Para streams IP suele ir bien asÃ­:
    cap = cv2.VideoCapture(source)
    if not cap.isOpened():
        print(f"âŒ No se pudo abrir la cÃ¡mara/fuente: {source}")
        return None
    print(f"âœ… CÃ¡mara/fuente abierta: {source}")
    return cap

cap = None
prev_state = False

try:
    while True:
        # Leer estado actual del bit de trigger del PLC
        current_state = ipc.read_by_name(PLC_TRIGGER_VAR, pyads.PLCTYPE_BOOL)

        # Flanco de subida: FALSE -> TRUE
        if current_state and not prev_state:
            print("ðŸš€ Flanco de subida detectado. Iniciando ciclo de captura...")

            # Abrir cÃ¡mara (en este caso DroidCam IP)
            cap = open_camera(CAMERA_SOURCE)
            if cap is None:
                # No cÃ¡mara â†’ esperamos al siguiente flanco
                time.sleep(0.5)
                prev_state = current_state
                continue

            predicciones = []
            start_time = time.time()

            # Capturamos hasta MAX_FRAMES o hasta MAX_CAPTURE_DURATION
            while True:
                # Si PLC baja el bit, dejamos de capturar
                if not ipc.read_by_name(PLC_TRIGGER_VAR, pyads.PLCTYPE_BOOL):
                    print("ðŸ§¯ Trigger bajado por el PLC. Terminando captura.")
                    break

                # LÃ­mite de tiempo
                elapsed = time.time() - start_time
                if elapsed > MAX_CAPTURE_DURATION:
                    print("â±ï¸ Tiempo mÃ¡ximo de captura alcanzado.")
                    break

                # LÃ­mite de frames
                if len(predicciones) >= MAX_FRAMES:
                    print("ðŸ“¸ MÃ¡ximo de frames alcanzado.")
                    break

                ret, frame = cap.read()
                if not ret or frame is None:
                    print("âš ï¸ No se pudo capturar frame. Terminando ciclo.")
                    break

                # (Opcional) Mostrar el frame
                cv2.imshow("DetecciÃ³n de tapa (DroidCam)", frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    print("ðŸšª Salida manual con tecla 'q'.")
                    break

                # Hacemos la predicciÃ³n
                color = predict_image(frame, model)
                predicciones.append(color)
                print(f"   â†’ PredicciÃ³n {len(predicciones)}: {color}")

                time.sleep(FRAME_SLEEP)

            # DecisiÃ³n final basado en votaciÃ³n
            if len(predicciones) >= MIN_PREDICTIONS:
                contador = Counter(predicciones)
                color_mas_frecuente, count = contador.most_common(1)[0]
                fraccion = count / len(predicciones)

                print(f"\nðŸ“Š Predicciones totales: {len(predicciones)}")
                print(f"   Frecuencias: {contador}")
                print(f"   Dominante: {color_mas_frecuente} ({fraccion*100:.1f}%)")

                if fraccion < DOMINANCE_THRESHOLD:
                    print("âš ï¸ Dominancia baja, se toma como background.")
                    color_final = "background"
                else:
                    color_final = color_mas_frecuente
            else:
                print(f"âš ï¸ Muy pocas predicciones ({len(predicciones)}), se toma background.")
                color_final = "background"

            # Enviar resultado al PLC
            plc_value = COLOR_TO_PLC_VALUE.get(color_final, 5)
            ipc.write_by_name(PLC_OUTPUT_VAR, plc_value, pyads.PLCTYPE_INT)
            print(f"ðŸ“¤ Enviado a PLC: {plc_value} ({color_final})\n")

            # Liberar cÃ¡mara
            if cap is not None:
                cap.release()
                cap = None
            cv2.destroyAllWindows()
            print("ðŸ›‘ Fin de ciclo. Esperando prÃ³ximo flanco...\n")

        # Actualizar estado anterior y pequeÃ±a pausa
        prev_state = current_state
        time.sleep(0.02)

except KeyboardInterrupt:
    print("ðŸ§¨ Interrumpido manualmente (Ctrl+C).")

except Exception as e:
    print(f"ðŸ’¥ Error general: {e}")

finally:
    if cap is not None:
        cap.release()
    cv2.destroyAllWindows()
    ipc.close()
    print("ðŸ”š Recursos liberados y conexiÃ³n PLC cerrada.")